






































































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [04:58<00:00,  4.27s/it]
  0%|                                                                                                                                                                     | 0/70 [00:00<?, ?it/s]

















  File "/Users/zorilolah/Documents/CryptoNewsFeed/src/run.py", line 54, in <module>                                                                              | 18/70 [01:16<03:43,  4.31s/it]
    trainer.train_model()
  File "/Users/zorilolah/Documents/CryptoNewsFeed/src/models/training.py", line 31, in train_model
    self.train_epoch_model(epoch = epoch)
  File "/Users/zorilolah/Documents/CryptoNewsFeed/src/models/training.py", line 40, in train_epoch_model
    loss.backward()
  File "/Users/zorilolah/anaconda3/envs/vit/lib/python3.9/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/Users/zorilolah/anaconda3/envs/vit/lib/python3.9/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
  File "/Users/zorilolah/anaconda3/envs/vit/lib/python3.9/site-packages/wandb/wandb_torch.py", line 282, in <lambda>
    handle = var.register_hook(lambda grad: _callback(grad, log_track))
KeyboardInterrupt